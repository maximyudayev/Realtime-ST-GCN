{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74f62da-5577-48d1-abe7-b1ff8d5035a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from data_prep.dataset import SkeletonDataset, SkeletonDatasetFromDirectory\n",
    "\n",
    "import st_gcn_parser\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "class Processor:\n",
    "    \"\"\"ST-GCN processing wrapper for training and testing the model.\n",
    "\n",
    "    Methods:\n",
    "        train()\n",
    "            Trains the model, given user-defined training parameters.\n",
    "\n",
    "        test()\n",
    "            Performs only the forward pass for inference.\n",
    "\n",
    "    TODO:\n",
    "        ``1.`` Provide useful prediction statistics (e.g. IoU, jitter, etc.).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        dataloader,\n",
    "        device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model : ``torch.nn.Module``\n",
    "                Configured PyTorch model.\n",
    "            \n",
    "            num_classes : ``int``\n",
    "                Number of action classification classes.\n",
    "\n",
    "            dataloader : ``torch.utils.data.DataLoader``\n",
    "                Data handle to account for its class imbalance in the CE loss.\n",
    "        \"\"\"\n",
    "\n",
    "        classes = torch.tensor(range(num_classes), dtype=torch.float32)\n",
    "        class_dist = torch.zeros(num_classes, dtype=torch.float32)\n",
    "\n",
    "        for _, labels in dataloader:\n",
    "            class_dist += torch.sum(\n",
    "                (labels[:,:,None].to(torch.float32) == classes[None].expand(labels.shape[1],-1)).to(torch.float32),\n",
    "                dim=(0,1))\n",
    "\n",
    "        self.model = model\n",
    "        self.ce = nn.CrossEntropyLoss(weight=(1-class_dist/torch.sum(class_dist)).to(device=device), reduction='mean')\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "\n",
    "    def update_lr_(self, learning_rate, learning_rate_decay, epoch):\n",
    "        \"\"\"Decays learning rate monotonically by the provided factor.\"\"\"\n",
    "        \n",
    "        rate = learning_rate * pow(learning_rate_decay, epoch)\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g['lr'] = rate\n",
    "\n",
    "\n",
    "    def forward_(\n",
    "        self,\n",
    "        captures,\n",
    "        labels,\n",
    "        device,\n",
    "        **kwargs):\n",
    "        \"\"\"Does the forward pass on the model.\n",
    "        \n",
    "        If `dataset_type` is `'dir'`, processes 1 trial at a time, chops each sequence \n",
    "        into equal segments that are split across available executors (GPUs) for parallel computation.\n",
    "        \n",
    "        If `model` is `'original'` and `latency` is `True`, applies the original classification model\n",
    "        on non-overlapping windows of size `receptive_field` over the input stream, producing outputs at a \n",
    "        reduced temporal resolution inversely proportional to the size of the window. Trades prediction\n",
    "        resolution for compute (does not compute redundant values for input frames otherwise overlapped by \n",
    "        multiple windows).\n",
    "        \"\"\"\n",
    "\n",
    "        # move both data to the compute device\n",
    "        # (captures is a batch of full-length captures, label is a batch of ground truths)\n",
    "        captures, labels = captures.to(device), labels.to(device)\n",
    "\n",
    "        N, _, L, _ = captures.size()\n",
    "\n",
    "        # Splits trial into overlapping subsequences of samples\n",
    "        if kwargs['dataset_type'] == 'dir': \n",
    "            if kwargs['model'] == 'original':\n",
    "                # zero pad the input across time from start by the receptive field size\n",
    "                captures = F.pad(captures, (0, 0, kwargs['receptive_field']-1, 0))\n",
    "                stride = kwargs['receptive_field'] if kwargs['latency'] else 1\n",
    "                captures = captures.unfold(2, kwargs['receptive_field'], stride)\n",
    "                labels = labels[:, ::stride]\n",
    "            else:\n",
    "                # Size to divide the trial into to construct a data parallel batch\n",
    "                # TODO: adjust if kernel is different in multi-stage ST-GCN\n",
    "                P = kwargs['segment']-(kwargs['kernel'][0]-1)-(L-kwargs['segment'])%(kwargs['segment']-(kwargs['kernel'][0]-1))\n",
    "                # Pad the end of the sequence to use all of the available readings (masks actual outputs later)\n",
    "                # TODO: if captures is perfectly unfolded without padding, below call will create a slice of all 0's. Put a conditional to prevent that.\n",
    "                captures = F.pad(captures, (0, 0, 0, P))\n",
    "                captures = captures.unfold(2, kwargs['segment'], kwargs['segment']-(kwargs['kernel'][0]-1))\n",
    "            \n",
    "            N, C, N_new, V, T_new = captures.size()\n",
    "            # (N,C,N',V,T') -> batches of unfolded slices\n",
    "            captures = captures.permute(0, 2, 1, 4, 3).contiguous()\n",
    "            captures = captures.view(N * N_new, C, T_new, V)\n",
    "            # (N'',C,T',V)\n",
    "\n",
    "        # make predictions and compute the loss\n",
    "        # forward pass the minibatch through the model for the corresponding subject\n",
    "        # the input tensor has shape (N, V, C, L): N-batch, V-nodes, C-channels, L-length\n",
    "        # the output tensor has shape (N, C', L)\n",
    "        predictions = self.model(Variable(captures, requires_grad=True))\n",
    "\n",
    "        if kwargs['dataset_type'] == 'dir':\n",
    "            C_new = predictions.size(1)\n",
    "            if kwargs['model'] == 'original':\n",
    "                # arrange tensor back into a time series\n",
    "                predictions = predictions.view(N, N_new, C_new)\n",
    "                predictions = predictions.permute(0, 2, 1)\n",
    "            else:\n",
    "                # clone the tensor from the unfolded view to avoid overwriting underlying data that is viewed in multiple slices\n",
    "                predictions = torch.clone(predictions)\n",
    "                # clear the overlapping Gamma-1 predictions at the start of each segment (except the very first segment), since \n",
    "                # overlapped regions are added when folding the tensor\n",
    "                predictions[1:,:,:kwargs['kernel'][0]-1] = 0\n",
    "                # shuffle data around for the correct contiguous access by the fold()\n",
    "                predictions = predictions[None].permute(0, 2, 3, 1).contiguous()\n",
    "                predictions = predictions.view(N, C_new * kwargs['segment'], -1)\n",
    "                # fold segments of the original trial computed in parallel on multiple executors back into original length sequence\n",
    "                # and drop the end padding used to fill tensor to equal row-column size\n",
    "                predictions = F.fold(\n",
    "                    predictions, \n",
    "                    output_size=(1, L+P), \n",
    "                    kernel_size=(1, kwargs['segment']), \n",
    "                    stride=(1, kwargs['segment']-(kwargs['kernel'][0]-1)))[:,:,0,:L]\n",
    "\n",
    "        # cross-entropy expects output as class indices (N, C, K), with labels (N, K): \n",
    "        # N-batch (flattened multi-skeleton minibatch), C-class, K-extra dimension (capture length)\n",
    "        # CE + MSE loss metric tuning is taken from @BenjaminFiltjens's MS-GCN:\n",
    "        # CE guides model toward absolute correctness on single frame predictions,\n",
    "        # MSE component punishes large variations in class probabilities between consecutive samples\n",
    "        ce = self.ce(predictions, labels)\n",
    "        # In the reduced temporal resolution setting of the original model, MSE loss is expected to be large the higher\n",
    "        # the receptive field since after that many frames a human could start performing a drastically diferent action\n",
    "        mse = 0.15 * torch.mean(\n",
    "            torch.clamp(\n",
    "                self.mse(\n",
    "                    F.log_softmax(predictions[:,:,1:], dim=1), \n",
    "                    F.log_softmax(predictions.detach()[:,:,:-1], dim=1)),\n",
    "                min=0,\n",
    "                max=16))\n",
    "\n",
    "        # calculate the predictions statistics\n",
    "        # this only sums the number of top-1 correctly predicted frames, but doesn't look at prediction jitter\n",
    "        _, top5_predicted = torch.topk(predictions, k=5, dim=1)\n",
    "        top1_predicted = top5_predicted[:,0,:]\n",
    "\n",
    "        top1_cor = torch.sum(top1_predicted == labels).data.item()\n",
    "        top5_cor = torch.sum(top5_predicted == labels[:,None,:]).data.item()\n",
    "        tot = labels.numel()\n",
    "\n",
    "        return top1_predicted, top5_predicted, top1_cor, top5_cor, tot, ce, mse\n",
    "\n",
    "\n",
    "    def validate_(\n",
    "        self,\n",
    "        dataloader,\n",
    "        device,\n",
    "        **kwargs):\n",
    "        \"\"\"Does a forward pass without recording gradients. \n",
    "\n",
    "        Shared between train and test scripts: train invokes it after each epoch trained,\n",
    "        test invokes it once for inference only.\n",
    "        \"\"\"\n",
    "\n",
    "        # do not record gradients\n",
    "        with torch.no_grad():    \n",
    "            top1_correct = 0\n",
    "            top5_correct = 0\n",
    "            total = 0\n",
    "\n",
    "            test_start_time = time.time()\n",
    "\n",
    "            confusion_matrix = torch.zeros(self.num_classes, self.num_classes, device=device)\n",
    "            total_per_class = torch.zeros(self.num_classes, 1, device=device)\n",
    "            \n",
    "            ce_epoch_loss_val = 0\n",
    "            mse_epoch_loss_val = 0\n",
    "\n",
    "            # sweep through the training dataset in minibatches\n",
    "            for captures, labels in dataloader:\n",
    "                top1_predicted, _, top1_cor, top5_cor, tot, ce, mse = self.forward_(captures, labels, device, **kwargs)\n",
    "\n",
    "                top1_correct += top1_cor\n",
    "                top5_correct += top5_cor\n",
    "                total += tot\n",
    "\n",
    "                stride = kwargs['receptive_field'] if kwargs['latency'] else 1\n",
    "                labels = labels[:, ::stride]\n",
    "                N, L = labels.size()\n",
    "                \n",
    "                # epoch loss has to multiply by minibatch size to get total non-averaged loss, \n",
    "                # which will then be averaged across the entire dataset size, since\n",
    "                # loss for dataset with equal-length trials averages the CE and MSE losses for each minibatch\n",
    "                # (used for statistics)\n",
    "                ce_epoch_loss_val += (ce*N).data.item()\n",
    "                mse_epoch_loss_val += (mse*N).data.item()\n",
    "\n",
    "                # delete unnecessary computational graph references to clear space\n",
    "                del ce, mse\n",
    "\n",
    "                # collect the correct predictions for each class and total per that class\n",
    "                # for batch_el in range(N*M):\n",
    "                for batch_el in range(N):\n",
    "                    top1_predicted_ohe = torch.zeros(L, self.num_classes, device=device)\n",
    "                    top1_predicted_ohe[range(L), top1_predicted[batch_el]] = 1\n",
    "                    confusion_matrix[labels[batch_el, 0]] += top1_predicted_ohe.sum(dim=0)\n",
    "                    total_per_class[labels[batch_el, 0]] += L\n",
    "\n",
    "            test_end_time = time.time()\n",
    "\n",
    "            # normalize each row of the confusion matrix to obtain class probabilities\n",
    "            confusion_matrix = torch.div(confusion_matrix, total_per_class)\n",
    "\n",
    "            top1_acc = top1_correct / total\n",
    "            top5_acc = top5_correct / total\n",
    "            duration = test_end_time - test_start_time\n",
    "\n",
    "        return top1_acc, top5_acc, duration, confusion_matrix, ce_epoch_loss_val, mse_epoch_loss_val\n",
    "\n",
    "\n",
    "    def train(\n",
    "        self, \n",
    "        save_dir, \n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        device,\n",
    "        epochs,\n",
    "        checkpoints,\n",
    "        checkpoint,\n",
    "        learning_rate,\n",
    "        learning_rate_decay,\n",
    "        **kwargs):\n",
    "        \"\"\"Trains the model, given user-defined training parameters.\"\"\"\n",
    "\n",
    "        # move the model to the compute device(s) if available (CPU, GPU, TPU, etc.)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Using\", torch.cuda.device_count(), \"allocated GPUs\", flush=True, file=kwargs['log'][0])\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        self.model.to(device)\n",
    "\n",
    "        if checkpoint:\n",
    "            state = torch.load(checkpoint, map_location=device)\n",
    "            range_epochs = range(state['epoch']+1, epochs)\n",
    "        else:\n",
    "            range_epochs = range(epochs)\n",
    "\n",
    "        # setup the optimizer\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        # load the checkpoint if not training from scratch\n",
    "        if checkpoint:\n",
    "            self.optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "\n",
    "        # variables for email updates\n",
    "        epoch_list = []\n",
    "\n",
    "        top1_acc_train_list = []\n",
    "        top1_acc_val_list = []\n",
    "        top5_acc_train_list = []\n",
    "        top5_acc_val_list = []\n",
    "        duration_train_list = []\n",
    "        duration_val_list = []\n",
    "\n",
    "        ce_loss_train_list = []\n",
    "        mse_loss_train_list = []\n",
    "        epoch_loss_train_list = []\n",
    "\n",
    "        ce_loss_val_list = []\n",
    "        mse_loss_val_list = []\n",
    "        epoch_loss_val_list = []\n",
    "\n",
    "        # train the model for num_epochs\n",
    "        # (dataloader is automatically shuffled after each epoch)\n",
    "        for epoch in range_epochs:\n",
    "            # set layers to training mode if behavior of any differs between train and prediction\n",
    "            # (prepares Dropout and BatchNormalization layers to disable and to learn parameters, respectively)\n",
    "            self.model.train()\n",
    "\n",
    "            ce_epoch_loss_train = 0\n",
    "            mse_epoch_loss_train = 0\n",
    "\n",
    "            ce_loss = 0\n",
    "            mse_loss = 0\n",
    "\n",
    "            top1_correct = 0\n",
    "            top5_correct = 0\n",
    "            total = 0\n",
    "\n",
    "            # decay learning rate every 10 epochs [ref: Yan 2018]\n",
    "            if (epoch % 10 == 0):\n",
    "                self.update_lr_(learning_rate, learning_rate_decay, epoch//10)\n",
    "\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # sweep through the training dataset in minibatches\n",
    "            for i, (captures, labels) in enumerate(train_dataloader):\n",
    "                N, _, _, _ = captures.size()\n",
    "\n",
    "                _, _, top1_cor, top5_cor, tot, ce, mse = self.forward_(captures, labels, device, **kwargs)\n",
    "\n",
    "                top1_correct += top1_cor\n",
    "                top5_correct += top5_cor\n",
    "                total += tot\n",
    "\n",
    "                # epoch loss has to multiply by minibatch size to get total non-averaged loss, \n",
    "                # which will then be averaged across the entire dataset size, since\n",
    "                # loss for dataset with equal-length trials averages the CE and MSE losses for each minibatch\n",
    "                # (used for statistics)\n",
    "                ce_epoch_loss_train += (ce*N).data.item()\n",
    "                mse_epoch_loss_train += (mse*N).data.item()\n",
    "\n",
    "                # accumulate losses (used for backpropagation)\n",
    "                ce_loss += ce\n",
    "                mse_loss += mse\n",
    "                # delete unnecessary computational graph references to clear space\n",
    "                del ce, mse\n",
    "\n",
    "                # zero the gradient buffers after every batch\n",
    "                # if dataset is a tensor with equal length trials, always enters\n",
    "                # if dataset is a set of different length trials, enters every ``batch_size`` iteration\n",
    "                if ((kwargs['dataset_type'] == 'dir' and\n",
    "                        ((i + 1) % kwargs['batch_size'] == 0 or \n",
    "                        (i + 1) == len(train_dataloader))) or\n",
    "                    (kwargs['dataset_type'] == 'file')):\n",
    "\n",
    "                    # loss is already a mean across minibatch for tensor of equally long trials, but\n",
    "                    # not for different-length trials -> needs averaging\n",
    "                    loss = ce_loss + mse_loss\n",
    "                    if (kwargs['dataset_type'] == 'dir' and (i + 1) % kwargs['batch_size'] == 0):\n",
    "                        # if the minibatch is the same size as requested (first till one before last minibatch)\n",
    "                        loss /= kwargs['batch_size']\n",
    "                    elif (kwargs['dataset_type'] == 'dir' and (i + 1) == len(train_dataloader)):\n",
    "                        # if the minibatch is smaller than requested (last minibatch)\n",
    "                        loss /= ((i + 1) % kwargs['batch_size'])\n",
    "\n",
    "                    # backward pass to compute the gradients\n",
    "                    loss.backward()\n",
    "\n",
    "                    # update parameters based on the computed gradients\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    # clear the loss\n",
    "                    ce_loss = 0\n",
    "                    mse_loss = 0\n",
    "                    del loss\n",
    "\n",
    "                    # clear the gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "            epoch_end_time = time.time()\n",
    "            duration_train = epoch_end_time - epoch_start_time\n",
    "            top1_acc_train = top1_correct / total\n",
    "            top5_acc_train = top5_correct / total\n",
    "            \n",
    "            # checkpoint the model during training at specified epochs\n",
    "            if epoch in checkpoints:\n",
    "                torch.save({\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"loss\": (ce_epoch_loss_train + mse_epoch_loss_train) / len(train_dataloader),\n",
    "                    }, \"{0}/epoch-{1}.pt\".format(save_dir, epoch))\n",
    "            \n",
    "            # set layers to inference mode if behavior differs between train and prediction\n",
    "            # (prepares Dropout and BatchNormalization layers to enable and to freeze parameters, respectively)\n",
    "            self.model.eval()\n",
    "\n",
    "            # test the model on the validation set\n",
    "            # will complain on CUDA devices that input gradients are none: irrelevant because it is a side effect of\n",
    "            # the shared `forward_()` routine for both tasks, where the model is set to `train()` or `eval()` in the\n",
    "            # corresponding caller function\n",
    "            top1_acc_val, top5_acc_val, duration_val, confusion_matrix, ce_epoch_loss_val, mse_epoch_loss_val = self.validate_(\n",
    "                dataloader=val_dataloader,\n",
    "                device=device,\n",
    "                **kwargs)\n",
    "\n",
    "            # record all stats of interest for logging/notification\n",
    "            epoch_list.insert(0, epoch)\n",
    "\n",
    "            ce_loss_train_list.insert(0, ce_epoch_loss_train / len(train_dataloader))\n",
    "            mse_loss_train_list.insert(0, mse_epoch_loss_train / len(train_dataloader))\n",
    "            epoch_loss_train_list.insert(0, (ce_epoch_loss_train + mse_epoch_loss_train) / len(train_dataloader))\n",
    "\n",
    "            ce_loss_val_list.insert(0, ce_epoch_loss_val / len(val_dataloader))\n",
    "            mse_loss_val_list.insert(0, mse_epoch_loss_val / len(val_dataloader))\n",
    "            epoch_loss_val_list.insert(0, (ce_epoch_loss_val + mse_epoch_loss_val) / len(val_dataloader))\n",
    "\n",
    "            top1_acc_train_list.insert(0, top1_acc_train)\n",
    "            top1_acc_val_list.insert(0, top1_acc_val)\n",
    "            top5_acc_train_list.insert(0, top5_acc_train)\n",
    "            top5_acc_val_list.insert(0, top5_acc_val)            \n",
    "            duration_train_list.insert(0, duration_train)\n",
    "            duration_val_list.insert(0, duration_val)\n",
    "\n",
    "            # save confusion matrix as a CSV file\n",
    "            pd.DataFrame(confusion_matrix.cpu().numpy()).to_csv('{0}/confusion_matrix_epoch-{1}.csv'.format(save_dir, epoch))\n",
    "\n",
    "            # log and send notifications\n",
    "            print(\n",
    "                \"[epoch {0}]: epoch loss = {1}, top1_acc_train = {2}, top5_acc_train = {3}, top1_acc_val = {4}, top5_acc_val = {5}\"\n",
    "                .format(\n",
    "                    epoch, \n",
    "                    (ce_epoch_loss_train + mse_epoch_loss_train) / len(train_dataloader),\n",
    "                    top1_acc_train,\n",
    "                    top5_acc_train,\n",
    "                    top1_acc_val,\n",
    "                    top5_acc_val),\n",
    "                flush=True,\n",
    "                file=kwargs['log'][0])\n",
    "            \n",
    "            if kwargs['verbose'] > 0:\n",
    "                print(\n",
    "                    \"[epoch {0}]: train_time = {1}, val_time = {2}\"\n",
    "                    .format(\n",
    "                        epoch,\n",
    "                        duration_train,\n",
    "                        duration_val),\n",
    "                    flush=True,\n",
    "                    file=kwargs['log'][0])\n",
    "            \n",
    "            # format a stats table (in newest to oldest order) and send it as email update\n",
    "            if kwargs['verbose'] > 1:\n",
    "                os.system(\n",
    "                    'header=\"\\n %-6s %5s %11s %11s %9s %9s %11s %9s\\n\";'\n",
    "                    'format=\" %-03d %4.6f %1.4f %1.4f %1.4f %1.4f %5.6f %5.6f\\n\";'\n",
    "                    'printf \"$header\" \"EPOCH\" \"LOSS\" \"TOP1_TRAIN\" \"TOP5_TRAIN\" \"TOP1_VAL\" \"TOP5_VAL\" \"TIME_TRAIN\" \"TIME_VAL\" > $PBS_O_WORKDIR/mail_draft_{1}.txt;'\n",
    "                    'printf \"$format\" {0} >> $PBS_O_WORKDIR/mail_draft_{1}.txt;'\n",
    "                    'cat $PBS_O_WORKDIR/mail_draft_{1}.txt | mail -s \"[{1}]: $PBS_JOBNAME status update\" {2}'\n",
    "                    .format(\n",
    "                        ' '.join([\n",
    "                            ' '.join([str(e) for e in t]) for t \n",
    "                            in zip(\n",
    "                                epoch_list,\n",
    "                                epoch_loss_train_list,\n",
    "                                top1_acc_train_list,\n",
    "                                top5_acc_train_list,\n",
    "                                top1_acc_val_list,\n",
    "                                top5_acc_val_list,\n",
    "                                duration_train_list,\n",
    "                                duration_val_list)]),\n",
    "                        os.getenv('PBS_JOBID').split('.')[0],\n",
    "                        kwargs['email']))\n",
    "\n",
    "            # save (update) train-validation curve as a CSV file after each epoch\n",
    "            pd.DataFrame(\n",
    "                data={\n",
    "                    'top1_train': top1_acc_train_list,\n",
    "                    'top1_val': top1_acc_val_list,\n",
    "                    'top5_train': top5_acc_train_list,\n",
    "                    'top5_val': top5_acc_val_list\n",
    "                }).to_csv('{0}/accuracy-curve.csv'.format(save_dir))\n",
    "\n",
    "            # save (update) loss curve as a CSV file after each epoch\n",
    "            pd.DataFrame(\n",
    "                data={\n",
    "                    'ce_train': ce_loss_train_list,\n",
    "                    'mse_train': mse_loss_train_list,\n",
    "                    'ce_val': ce_loss_val_list,\n",
    "                    'mse_val': mse_loss_val_list,\n",
    "                }).to_csv('{0}/train-validation-curve.csv'.format(save_dir))\n",
    "\n",
    "        # save the final model\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"loss\": (ce_epoch_loss_train + mse_epoch_loss_train) / len(train_dataloader),\n",
    "            }, \"{0}/final.pt\".format(save_dir))\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def test(\n",
    "        self,\n",
    "        save_dir,\n",
    "        dataloader,\n",
    "        device,\n",
    "        **kwargs):\n",
    "        \"\"\"Performs only the forward pass for inference.\n",
    "        \"\"\"\n",
    "        \n",
    "        # set layers to inference mode if behavior differs between train and prediction\n",
    "        # (prepares Dropout and BatchNormalization layers to enable and to freeze parameters, respectively)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # move the model to the compute device(s) if available (CPU, GPU, TPU, etc.)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Using\", torch.cuda.device_count(), \"allocated GPUs\", flush=True, file=kwargs['log'][0])\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        self.model.to(device)\n",
    "\n",
    "        # test the model on the validation set\n",
    "        top1_acc_val, top5_acc_val, duration_val, confusion_matrix, ce_epoch_loss_val, mse_epoch_loss_val = self.validate_(\n",
    "            dataloader=dataloader,\n",
    "            device=device,\n",
    "            **kwargs)\n",
    "        \n",
    "        # save confusion matrix as a CSV file\n",
    "        pd.DataFrame(confusion_matrix.cpu().numpy()).to_csv('{0}/confusion_matrix.csv'.format(save_dir))\n",
    "\n",
    "        # log and send notifications\n",
    "        print(\n",
    "            \"[test]: top1_acc = {0}, top5_acc = {1}\"\n",
    "            .format( \n",
    "                top1_acc_val,\n",
    "                top5_acc_val),\n",
    "            flush=True,\n",
    "            file=kwargs['log'][0])\n",
    "        \n",
    "        if kwargs['verbose'] > 0:\n",
    "            print(\n",
    "                \"[test]: time = {1}\"\n",
    "                .format(duration_val),\n",
    "                flush=True,\n",
    "                file=kwargs['log'][0])\n",
    "\n",
    "        # format a stats table (in newest to oldest order) and send it as email update\n",
    "        if kwargs['verbose'] > 1:\n",
    "            os.system(\n",
    "                'header=\"\\n %-5s %5s %5s\\n\";'\n",
    "                'format=\" %-1.4f %1.4f %5.6f\\n\";'\n",
    "                'printf \"$header\" \"TOP1\" \"TOP5\" \"TIME\" > $PBS_O_WORKDIR/mail_draft_{1}.txt;'\n",
    "                'printf \"$format\" {0} >> $PBS_O_WORKDIR/mail_draft_{1}.txt;'\n",
    "                'cat $PBS_O_WORKDIR/mail_draft_{1}.txt | mail -s \"[{1}]: $PBS_JOBNAME status update\" {2}'\n",
    "                .format(\n",
    "                    ' '.join([\n",
    "                        ' '.join([str(e) for e in t]) for t \n",
    "                        in zip(\n",
    "                            top1_acc_val,\n",
    "                            top5_acc_val,\n",
    "                            duration_val)]),\n",
    "                    os.getenv('PBS_JOBID').split('.')[0],\n",
    "                    kwargs['email']))\n",
    "        return\n",
    "\n",
    "\n",
    "def common(args):\n",
    "    \"\"\"Performs setup common to any ST-GCN model variant.\n",
    "    \n",
    "    Only needs to be invoked once for a given problem (train-test, benchmark, etc.). \n",
    "    Corresponds to the parts of the pipeline irrespective of the black-box model used.\n",
    "    Creates DataLoaders, sets up processing device and random number generator,\n",
    "    reads action classes file.\n",
    "\n",
    "    Args:\n",
    "        args : ``dict``\n",
    "            Parsed CLI arguments.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of action classes.\n",
    "\n",
    "        PyTorch device (CPU or GPU).\n",
    "\n",
    "        Train and validation DataLoaders.\n",
    "    \"\"\"\n",
    "    \n",
    "    # setting up random number generator for deterministic and meaningful benchmarking\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # preparing datasets for training and validation\n",
    "    if args.dataset_type == 'file':\n",
    "        train_data = SkeletonDataset('{0}/train_data.npy'.format(args.data), '{0}/train_label.pkl'.format(args.data))\n",
    "        val_data = SkeletonDataset('{0}/val_data.npy'.format(args.data), '{0}/val_label.pkl'.format(args.data))\n",
    "    elif args.dataset_type == 'dir':\n",
    "        train_data = SkeletonDatasetFromDirectory('{0}/train/features'.format(args.data), '{0}/train/labels'.format(args.data))\n",
    "        val_data = SkeletonDatasetFromDirectory('{0}/val/features'.format(args.data), '{0}/val/labels'.format(args.data))\n",
    "\n",
    "    # trials of different length can not be placed in the same tensor when batching, have to manually iterate over them\n",
    "    batch_size = 1 if args.dataset_type == 'dir' else args.batch_size\n",
    "    \n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # extract skeleton graph data\n",
    "    with open(args.graph, 'r') as graph_file:\n",
    "        graph = json.load(graph_file)\n",
    "\n",
    "    # extract actions from the label file\n",
    "    with open(args.actions, 'r') as action_names:\n",
    "        actions = action_names.read().split('\\n')\n",
    "\n",
    "    # 0th class is always background action\n",
    "    actions_dict = {0: \"background\"}\n",
    "    for i, action in enumerate(actions):\n",
    "        actions_dict[i+1] = action\n",
    "\n",
    "    # prepare a directory to store results\n",
    "    if not os.getenv('PBS_JOBID'):\n",
    "        with open('.vscode/pbs_jobid.txt', 'r+') as f:\n",
    "            job_id = f.readline()\n",
    "            os.environ['PBS_JOBID'] = job_id\n",
    "            f.seek(0)\n",
    "            f.write(str(int(job_id)+1))\n",
    "            f.truncate()\n",
    "    \n",
    "    save_dir = \"{0}/{1}/run_{2}\".format(args.out, args.model, os.getenv('PBS_JOBID').split('.')[0])\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    return graph, actions_dict, device, train_dataloader, val_dataloader, save_dir\n",
    "\n",
    "\n",
    "def build_model(args):\n",
    "    \"\"\"Builds the selected ST-GCN model variant.\n",
    "    \n",
    "    Args:\n",
    "        args : ``dict``\n",
    "            Parsed CLI arguments.\n",
    "\n",
    "    Returns:\n",
    "        PyTorch Model corresponding to the user-defined CLI parameters.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: \n",
    "            If GCN parameter list sizes do not match the number of stages.\n",
    "    \"\"\"\n",
    "\n",
    "    if (len(args.in_ch) != args.stages or\n",
    "        len(args.out_ch) != args.stages or\n",
    "        len(args.stride) != args.stages or\n",
    "        len(args.residual) != args.stages):\n",
    "        raise ValueError(\n",
    "            'GCN parameter list sizes do not match the number of stages. '\n",
    "            'Check your config file.')\n",
    "    elif (args.model == 'realtime' and args.buffer != 1):\n",
    "        raise ValueError(\n",
    "            'Selected the realtime model, but set buffer size to 1. '\n",
    "            'Check your config file.')\n",
    "    \n",
    "    if args.model == 'original':\n",
    "        model = OriginalStgcn(**vars(args))\n",
    "    elif args.model == 'adapted':\n",
    "        model = AdaptedStgcn(**vars(args))\n",
    "    else:\n",
    "        # all 3 adapted versions are encapsulated in the same class, training is identical (batch mode),\n",
    "        # usecase changes applied during inference\n",
    "        model = Stgcn(**vars(args))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    \"\"\"Entry point for training functionality of a single selected model.\n",
    "\n",
    "    Args:\n",
    "        args : ``dict``\n",
    "            Parsed CLI arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    # perform common setup around the model's black box\n",
    "    args.graph, actions, device, train_dataloader, val_dataloader, save_dir = common(args)\n",
    "    args.num_classes = len(actions)\n",
    "\n",
    "    # construct the target model using the CLI arguments\n",
    "    model = build_model(args)\n",
    "    # load the checkpoint if not trained from scratch\n",
    "    if args.checkpoint:\n",
    "        model.load_state_dict(torch.load(args.checkpoint, map_location=device)['model_state_dict'])\n",
    "    #     model.load_state_dict({\n",
    "    #         k.split('module.')[1]: v \n",
    "    #         for k, v in\n",
    "    #         torch.load(args.checkpoint, map_location=device)['model_state_dict'].items()})\n",
    "\n",
    "    # construct a processing wrapper\n",
    "    trainer = Processor(model, args.num_classes, train_dataloader, device)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # last dimension is the number of subjects in the scene (2 for datasets used)\n",
    "    print(\"Training started\", flush=True, file=args.log[0])\n",
    "    \n",
    "    # perform the training\n",
    "    # (the model is trained on all skeletons in the scene, simultaneously)\n",
    "    trainer.train(\n",
    "        save_dir=save_dir,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        device=device,    \n",
    "        **vars(args))\n",
    "    \n",
    "    print(\"Training completed in: {0}\".format(time.time() - start_time), flush=True, file=args.log[0])\n",
    "    \n",
    "    os.system(\n",
    "        'mail -s \"[{0}]: $PBS_JOBNAME - COMPLETED\" {1} <<< \"\"'\n",
    "        .format(\n",
    "            os.getenv('PBS_JOBID').split('.')[0],\n",
    "            args.email))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def test(args):\n",
    "    \"\"\"Entry point for testing functionality of a single pretrained model.\n",
    "\n",
    "    Args:\n",
    "        args : ``dict``\n",
    "            Parsed CLI arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    # perform common setup around the model's black box\n",
    "    args.graph, actions, device, val_dataloader, _, save_dir = common(args)\n",
    "    args.num_classes = len(actions)\n",
    "\n",
    "    # construct the target model using the CLI arguments\n",
    "    model = build_model(args)\n",
    "    # model.load_state_dict(torch.load(args.checkpoint, map_location=device)['model_state_dict'])\n",
    "    # load the checkpoint if not trained from scratch\n",
    "    if args.checkpoint:\n",
    "        model.load_state_dict({\n",
    "            k.split('module.')[1]: v \n",
    "            for k, v in\n",
    "            torch.load(args.checkpoint, map_location=device)['model_state_dict'].items()})\n",
    "\n",
    "    # construct a processing wrapper\n",
    "    trainer = Processor(model, args.num_classes, val_dataloader, device)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # last dimension is the number of subjects in the scene (2 for datasets used)\n",
    "    print(\"Testing started\", flush=True, file=args.log[0])\n",
    "    \n",
    "    # perform the testing\n",
    "    trainer.test(save_dir, val_dataloader, device, **vars(args))\n",
    "    \n",
    "    print(\"Testing completed in: {0}\".format(time.time() - start_time), flush=True, file=args.log[0])\n",
    "    \n",
    "    os.system(\n",
    "        'mail -s \"[{0}]: $PBS_JOBNAME - COMPLETED\" {1} <<< \"\"'\n",
    "        .format(\n",
    "            os.getenv('PBS_JOBID').split('.')[0], \n",
    "            args.email))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def benchmark(args):\n",
    "    \"\"\"Entry point for benchmarking functionality of multiple pretrained models.\n",
    "\n",
    "    TODO: complete\n",
    "\n",
    "    Args:\n",
    "        args : ``dict``\n",
    "            Parsed CLI arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    # perform common setup around the model's black box\n",
    "    args.graph, actions, device, _, val_dataloader, save_dir = common(args)\n",
    "    args.num_classes = len(actions)\n",
    "    \n",
    "    # split between the subjects in the captures\n",
    "    data, _ = next(iter(val_dataloader))\n",
    "    args.capture_length = data.shape[2]\n",
    "\n",
    "    # construct the target models using the CLI arguments\n",
    "    models = []\n",
    "    for m in args.models:\n",
    "        model = build_model(m)\n",
    "        \n",
    "        model.load_state_dict({\n",
    "            k.split('module.')[1]: v \n",
    "            for k, v in\n",
    "            torch.load(args.checkpoint, map_location=device)['model_state_dict'].items()})\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    # construct a processing wrapper\n",
    "    trainer = Processor(model, args.num_classes)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # last dimension is the number of subjects in the scene (2 for datasets used)\n",
    "    print(\"Testing started\", flush=True, file=args.log[0])\n",
    "    \n",
    "    # perform the testing\n",
    "    trainer.test(save_dir, val_dataloader, device, **vars(args))\n",
    "\n",
    "    print(\"Benchmarking completed in: {0}\".format(time.time() - start_time), flush=True, file=args.log[0])\n",
    "    \n",
    "    os.system(\n",
    "        'mail -s \"[{0}]: $PBS_JOBNAME - COMPLETED\" {1} <<< \"\"'\n",
    "        .format(\n",
    "            os.getenv('PBS_JOBID').split('.')[0],\n",
    "            args.email))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e286a11-9c2d-447c-9154-39e914e883d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:94: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:94: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "/tmp/ipykernel_28260/3391195577.py:94: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert((len(kwargs['in_ch'][i]) == layers_in_stage) and\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.utils.tgcn import ConvTemporalGraphical\n",
    "from models.utils.graph import Graph\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "\n",
    "class Stgcn(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional network of Yan, et al. (2018), adapted for realtime.\n",
    "    (https://arxiv.org/abs/1801.07455).\n",
    "\n",
    "    Implements both, realtime and buffered realtime logic in the same source. \n",
    "    At runtime, the model looks at the L-dimension of the tensor to make the predictions.\n",
    "    This enforces computations are numerically correct if the frame buffer is not completely full\n",
    "    (e.g. the last minibatch of frames from a recording if ``capture_length % buffer != 0``).\n",
    "    \n",
    "    All arguments are positional to enforce separation of concern and pass the responsibility for\n",
    "    model configuration up in the chain to the envoking program (config file).\n",
    "\n",
    "    TODO:\n",
    "        ``1.`` add logic for variation in FIFO latency.\n",
    "\n",
    "    Shape:\n",
    "        - Input[0]:    :math:`(N, C_{in}, L, V)`.\n",
    "        - Output[0]:   :math:`(N, C_{out}, L)`. \n",
    "        \n",
    "        where\n",
    "            :math:`N` is a batch size.\n",
    "\n",
    "            :math:`C_{in}` is the number of input channels (features).\n",
    "\n",
    "            :math:`C_{out}` is the number of classification classes.\n",
    "\n",
    "            :math:`L` is the number of frames (capture length).\n",
    "\n",
    "            :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Kwargs:\n",
    "            in_feat : ``int`` \n",
    "                Number of input sample channels/features.\n",
    "            \n",
    "            num_classes : ``int``\n",
    "                Number of output classification classes.\n",
    "            \n",
    "            kernel : ``list[int]``\n",
    "                Temporal kernel size Gamma.\n",
    "            \n",
    "            importance : ``bool``\n",
    "                If ``True``, adds a learnable importance weighting to the edges of the graph.\n",
    "            \n",
    "            latency : ``bool``\n",
    "                If ``True``, residual connection adds \n",
    "                ``x_{t}`` frame to ``y_{t}`` (which adds ``ceil(kernel_size/2)`` latency), \n",
    "                adds ``x_{t}`` frame to ``y_{t-ceil(kernel_size/2)}`` otherwise.\n",
    "            \n",
    "            layers : ``list[int]``\n",
    "                Array of number of ST-GCN layers, oner per stage.\n",
    "\n",
    "            in_ch : ``list[list[int]]``\n",
    "                2D array of input channel numbers, one per stage per ST-GCN layer.\n",
    "\n",
    "            out_ch : ``list[list[int]]``\n",
    "                2D array of output channel numbers, one per stage per ST-GCN layer.\n",
    "\n",
    "            stride : ``list[list[int]]``\n",
    "                2D array of temporal stride sizes, one per stage per ST-GCN layer.\n",
    "\n",
    "            residual : ``list[list[int]]``\n",
    "                2D array of residual connection flags, one per stage per ST-GCN layer.\n",
    "\n",
    "            dropout : ``list[list[float]]``\n",
    "                2D array of dropout parameters, one per stage per ST-GCN layer.\n",
    "\n",
    "            graph : ``dict`` \n",
    "                Dictionary with parameters for skeleton Graph.\n",
    "\n",
    "            strategy : ``str``\n",
    "                Type of Graph partitioning strategy.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        # save the config arguments for model conversions\n",
    "        self.conf = kwargs\n",
    "\n",
    "        # verify that parameter dimensions match (correct number of layers/parameters per stage)\n",
    "        for i, layers_in_stage in enumerate(kwargs['layers']):\n",
    "            assert((len(kwargs['in_ch'][i]) == layers_in_stage) and\n",
    "                    (len(kwargs['out_ch'][i]) == layers_in_stage) and\n",
    "                    (len(kwargs['stride'][i]) == layers_in_stage) and\n",
    "                    (len(kwargs['residual'][i]) == layers_in_stage),\n",
    "                (\"Incorrect number of constructor parameters in the ST-GCN stage ModuleList.\\n\"\n",
    "                \"Expected for stage {0}: {1}, got: ({2}, {3}, {4}, {5})\")\n",
    "                .format(\n",
    "                    i, \n",
    "                    kwargs['layers'][i], \n",
    "                    len(kwargs['in_ch'][i]), \n",
    "                    len(kwargs['out_ch'][i]), \n",
    "                    len(kwargs['stride'][i]), \n",
    "                    len(kwargs['residual'][i])))\n",
    "\n",
    "        # register the normalized adjacency matrix as a non-learnable saveable parameter \n",
    "        self.graph = Graph(strategy=kwargs['strategy'], **kwargs['graph'])\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # input capture normalization\n",
    "        # (N,C,L,V)\n",
    "        self.bn_in = nn.BatchNorm1d(kwargs['in_feat'] * A.size(1))\n",
    "        \n",
    "        # fcn for feature remapping of input to the network size\n",
    "        self.fcn_in = nn.Conv2d(in_channels=kwargs['in_feat'], out_channels=kwargs['in_ch'][0][0], kernel_size=1)\n",
    "        \n",
    "        # stack of ST-GCN layers\n",
    "        stack = [[StgcnLayer(\n",
    "                    num_joints=kwargs['graph']['num_node'],\n",
    "                    in_channels=kwargs['in_ch'][i][j],\n",
    "                    out_channels=kwargs['out_ch'][i][j],\n",
    "                    kernel_size=kwargs['kernel'][i],\n",
    "                    stride=kwargs['stride'][i][j],\n",
    "                    num_partitions=self.A.shape[0],\n",
    "                    residual=not not kwargs['residual'][i][j],\n",
    "                    dropout=kwargs['dropout'][i][j])\n",
    "                for j in range(layers_in_stage)] \n",
    "                for i, layers_in_stage in enumerate(kwargs['layers'])]\n",
    "        # flatten into a single sequence of layers after parameters were used to construct\n",
    "        # (done like that to make config files more readable)\n",
    "        self.st_gcn = nn.ModuleList([module for sublist in stack for module in sublist])\n",
    "        \n",
    "        # global pooling\n",
    "        # converts (N,C,L,V) -> (N,C,L,1)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=(1, kwargs['graph']['num_node']))\n",
    "\n",
    "        # fcn for prediction\n",
    "        # maps C to num_classes channels: (N,C,L,1) -> (N,F,L,1) \n",
    "        self.fcn_out = nn.Conv2d(\n",
    "            in_channels=kwargs['out_ch'][-1][-1],\n",
    "            out_channels=kwargs['num_classes'],\n",
    "            kernel_size=1)\n",
    "\n",
    "        # learnable edge importance weighting matrices (each layer, separate weighting)\n",
    "        if kwargs['importance']:\n",
    "            self.edge_importance = nn.ParameterList(\n",
    "                [nn.Parameter(\n",
    "                    torch.ones(\n",
    "                        kwargs['graph']['num_node'], \n",
    "                        kwargs['graph']['num_node'], \n",
    "                        requires_grad=True)) \n",
    "                for _ in self.st_gcn])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization\n",
    "        N, C, T, V = x.size()\n",
    "        # permutes must copy the tensor over as contiguous because .view() needs a contiguous tensor\n",
    "        # this incures extra overhead\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        # (N,V,C,T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.bn_in(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # (N,C,T,V)\n",
    "\n",
    "        # remap the features to the network size\n",
    "        x = self.fcn_in(x)\n",
    "\n",
    "        # feed the frame into the ST-GCN block\n",
    "        for st_gcn, importance in zip(self.st_gcn, self.edge_importance):\n",
    "            # adjacency matrix is a 3D tensor (size depends on the partition strategy)\n",
    "            x = checkpoint(st_gcn, x, self.A * importance)\n",
    "\n",
    "        # pool the output frame for a single feature vector\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        # remap the feature vector to class predictions\n",
    "        x = self.fcn_out(x)\n",
    "\n",
    "        # removes the last dimension (node dimension) of size 1: (N,C,L,1) -> (N,C,L)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "\n",
    "    # def _swap_layers_for_inference(self: nn.Module) -> nn.Module:\n",
    "        \n",
    "    #     return\n",
    "\n",
    "\n",
    "    # def train(self: nn.Module, mode: bool = True) -> nn.Module:\n",
    "    #     # TODO: \n",
    "    #     return super().train(mode)\n",
    "\n",
    "    \n",
    "    # def eval(self: nn.Module) -> nn.Module:\n",
    "    #     super().eval()\n",
    "\n",
    "    #     # stack of ST-GCN layers\n",
    "    #     stack = [[RtStgcnLayer(\n",
    "    #                 num_joints=self.conf['graph']['num_node'],\n",
    "    #                 fifo_latency=self.conf['latency'],\n",
    "    #                 in_channels=self.conf['in_ch'][i][j],\n",
    "    #                 out_channels=self.conf['out_ch'][i][j],\n",
    "    #                 kernel_size=self.conf['kernel'][i],\n",
    "    #                 stride=self.conf['stride'][i][j],\n",
    "    #                 num_partitions=self.A.shape[0],\n",
    "    #                 residual=not not self.conf['residual'][i][j],\n",
    "    #                 dropout=self.conf['dropout'][i][j],\n",
    "    #                 **self.conf)\n",
    "    #             for j in range(layers_in_stage)] \n",
    "    #             for i, layers_in_stage in enumerate(self.conf['layers'])]\n",
    "    #     # flatten into a single sequence of layers after parameters were used to construct\n",
    "    #     # (done like that to make config files more readable)\n",
    "    #     new_st_gcn = nn.ModuleList([module for sublist in stack for module in sublist])\n",
    "\n",
    "    #     # TODO: copy trained weights over from batch training to the inference layers\n",
    "    #     # for self.parameters()\n",
    "\n",
    "    #     return self\n",
    "\n",
    "    \n",
    "class RtStgcnLayer(nn.Module):\n",
    "    \"\"\"[!Inference only!] Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    \n",
    "    Each layer has a FIFO to store the corresponding Gamma-sized window of graph frames.\n",
    "    All arguments are positional to enforce separation of concern and pass the responsibility for\n",
    "    model configuration up in the chain to the envoking program (config file).\n",
    "\n",
    "    TODO:\n",
    "        ``1.`` add logic for variation in FIFO latency.\n",
    "\n",
    "        ``2.`` write more elaborate class description about the design choices and working principle.\n",
    "\n",
    "    Shape:\n",
    "        - Input[0]:     :math:`(N, C_{in}, L, V)` - Input graph frame.\n",
    "        - Input[1]:     :math:`(P, V, V)` - Graph adjacency matrix.\n",
    "        - Output[0]:    :math:`(N, C_{out}, L, V)` - Output graph frame.\n",
    "\n",
    "        where\n",
    "            :math:`N` is the batch size.\n",
    "            \n",
    "            :math:`L` is the buffer size (buffered frames number).\n",
    "\n",
    "            :math:`C_{in}` is the number of input channels (features).\n",
    "\n",
    "            :math:`C_{out}` is the number of output channels (features).\n",
    "\n",
    "            :math:`V` is the number of graph nodes.\n",
    "\n",
    "            :math:`P` is the number of graph partitions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        num_joints,\n",
    "        stride,\n",
    "        num_partitions,\n",
    "        dropout,\n",
    "        residual,\n",
    "        fifo_latency,\n",
    "        **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels : ``int``\n",
    "                Number of input sample channels/features.\n",
    "            \n",
    "            out_channels : ``int``\n",
    "                Number of channels produced by the convolution.\n",
    "            \n",
    "            kernel_size : ``int``\n",
    "                Size of the temporal window Gamma.\n",
    "            \n",
    "            num_joints : ``int``\n",
    "                Number of joint nodes in the graph.\n",
    "            \n",
    "            stride : ``int``\n",
    "                Stride of the temporal reduction.\n",
    "            \n",
    "            num_partitions : ``int``\n",
    "                Number of partitions in selected strategy.\n",
    "                Must correspond to the first dimension of the adjacency tensor.\n",
    "            \n",
    "            dropout : ``float``\n",
    "                Dropout rate of the final output.\n",
    "            \n",
    "            residual : ``bool``\n",
    "                If ``True``, applies a residual connection.\n",
    "            \n",
    "            fifo_latency : ``bool``\n",
    "                If ``True``, residual connection adds ``x_{t}`` frame to ``y_{t}`` (which adds ``ceil(kernel_size/2)`` latency), \n",
    "                otherwise adds ``x_{t}`` frame to ``y_{t-ceil(kernel_size/2)}``.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        # temporal kernel Gamma is symmetric (odd number)\n",
    "        # assert len(kernel_size) == 1\n",
    "        assert kernel_size % 2 == 1\n",
    "\n",
    "        self.num_partitions = num_partitions\n",
    "        self.num_joints = num_joints\n",
    "        self.stride = stride\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.fifo_size = stride*(kernel_size-1)+1\n",
    "        \n",
    "        # convolution of incoming frame \n",
    "        # (out_channels is a multiple of the partition number\n",
    "        # to avoid for-looping over several partitions)\n",
    "        # partition-wise convolution results are basically stacked across channel-dimension\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels*num_partitions, kernel_size=1)\n",
    "\n",
    "        # FIFO for intermediate Gamma graph frames after multiplication with adjacency matrices\n",
    "        # (N,G,P,C,V) - (N)batch, (G)amma, (P)artition, (C)hannels, (V)ertices\n",
    "        self.fifo = torch.zeros(kwargs['batch_size'], self.fifo_size, num_partitions, out_channels, num_joints)\n",
    "        \n",
    "        # normalization and dropout on main branch\n",
    "        self.bn_do = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(dropout, inplace=True))\n",
    "\n",
    "        # residual branch\n",
    "        if not residual:\n",
    "            self.residual = lambda _: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # activation of branch sum\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        \"\"\"\n",
    "        In case of buffered realtime processing, Conv2D and MMUL are done on the buffered frames,\n",
    "        which mimics the kernels reuse mechanism that would be followed in hardware at the expense\n",
    "        of extra memory for storing intermediate results.\n",
    "\n",
    "        TODO:\n",
    "            ``1.`` Speed up the for-loop part (buffered realtime setup) by vectorization.\n",
    "        \"\"\"\n",
    "        # residual branch\n",
    "        res = self.residual(x)\n",
    "        \n",
    "        # spatial convolution of incoming frame (node-wise)\n",
    "        a = self.conv(x)\n",
    "\n",
    "        # convert to the expected dimension order and add the partition dimension\n",
    "        # reshape the tensor for multiplication with the adjacency matrix\n",
    "        # (convolution output contains all partitions, stacked across the channel dimension)\n",
    "        # split into separate 4D tensors, each corresponding to a separate partition\n",
    "        b = torch.split(a, self.out_channels, dim=1)\n",
    "        # concatenate these 4D tensors across the partition dimension\n",
    "        c = torch.stack(b, -1)\n",
    "        # change the dimension order for the correct broadcating of the adjacency matrix\n",
    "        # (N,C,L,V,P) -> (N,L,P,C,V)\n",
    "        d = c.permute(0,2,4,1,3)\n",
    "        # single multiplication with the adjacency matrices (spatial selective addition, across partitions)\n",
    "        e = torch.matmul(d, A)\n",
    "\n",
    "        # perform temporal accumulation for each of the buffered frames\n",
    "        # (portability for buffered_realtime setup, for realtime, the buffer is of size 1)\n",
    "        outputs = []\n",
    "        for i in range(e.shape[1]):\n",
    "            # push the frame into the FIFO\n",
    "            self.fifo = torch.cat((e[:,i:i+1], self.fifo[:,:self.fifo_size-1]), 1)\n",
    "            \n",
    "            # slice the tensor according to the temporal stride size\n",
    "            # (if stride is 1, returns the whole tensor itself)\n",
    "            f = self.fifo[:,range(0, self.fifo_size, self.stride)]\n",
    "\n",
    "            # sum temporally and across partitions\n",
    "            # (C,H)\n",
    "            g = torch.sum(f, dim=(1,2))\n",
    "            outputs.append(g)\n",
    "\n",
    "        # stack frame-wise tensors into the original length L\n",
    "        # [(N,C,V)] -> (N,C,L,V)\n",
    "        h = torch.stack(outputs, 2)\n",
    "\n",
    "        # add the branches (main + residual)\n",
    "        i = h + res\n",
    "\n",
    "        return self.relu(i)\n",
    "\n",
    "\n",
    "class StgcnLayer(nn.Module):\n",
    "    \"\"\"[Training] Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    \n",
    "    Processes the entire video capture during training; it is mandatory to retain intermediate values\n",
    "    for backpropagation (hence no FIFOs allowed in training). Results of training with either layer\n",
    "    are identical, it is simply a nuissance of autodiff frameworks.\n",
    "    All arguments are positional to enforce separation of concern and pass the responsibility for\n",
    "    model configuration up in the chain to the envoking program (config file).\n",
    "\n",
    "    TODO:\n",
    "        ``1.`` validate documentation.\n",
    "\n",
    "    Shape:\n",
    "        - Input[0]:     :math:`(N, C_{in}, L, V)` - Input graph frame.\n",
    "        - Input[1]:     :math:`(P, V, V)` - Graph adjacency matrix.\n",
    "        - Output[0]:    :math:`(N, C_{out}, L, V)` - Output graph frame.\n",
    "\n",
    "        where\n",
    "            :math:`N` is the batch size.\n",
    "\n",
    "            :math:`C_{in}` is the number of input channels (features).\n",
    "\n",
    "            :math:`C_{out}` is the number of output channels (features).\n",
    "\n",
    "            :math:`L` is the video capture length.\n",
    "\n",
    "            :math:`V` is the number of graph nodes.\n",
    "\n",
    "            :math:`P` is the number of graph partitions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        num_joints,\n",
    "        stride,\n",
    "        num_partitions,\n",
    "        dropout,\n",
    "        residual):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels : ``int``\n",
    "                Number of input sample channels/features.\n",
    "            \n",
    "            out_channels : ``int``\n",
    "                Number of channels produced by the convolution.\n",
    "            \n",
    "            kernel_size : ``int``\n",
    "                Size of the temporal window Gamma.\n",
    "            \n",
    "            num_joints : ``int``\n",
    "                Number of joint nodes in the graph.\n",
    "            \n",
    "            stride : ``int``\n",
    "                Stride of the temporal reduction.\n",
    "            \n",
    "            num_partitions : ``int``\n",
    "                Number of partitions in selected strategy.\n",
    "                Must correspond to the first dimension of the adjacency tensor.\n",
    "            \n",
    "            dropout : ``float``\n",
    "                Dropout rate of the final output.\n",
    "            \n",
    "            residual : ``bool``\n",
    "                If ``True``, applies a residual connection.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        # temporal kernel Gamma is symmetric (odd number)\n",
    "        # assert len(kernel_size) == 1\n",
    "        assert kernel_size % 2 == 1\n",
    "\n",
    "        self.num_partitions = num_partitions\n",
    "        self.num_joints = num_joints\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # convolution of incoming frame \n",
    "        # (out_channels is a multiple of the partition number\n",
    "        # to avoid for-looping over several partitions)\n",
    "        # partition-wise convolution results are basically stacked across channel-dimension\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels*num_partitions, kernel_size=1, bias=False)\n",
    "        \n",
    "        # normalization and dropout on main branch\n",
    "        self.bn_relu = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # residual branch\n",
    "        if not residual:\n",
    "            self.residual = lambda _: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # activation of branch sum\n",
    "        # if no resnet connection, prevent ReLU from being applied twice\n",
    "        if not residual:\n",
    "            self.do = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.do = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout))\n",
    "\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        # TODO: replace with unfold -> fold calls\n",
    "        # lower triangle matrix for temporal accumulation that mimics FIFO behavior\n",
    "        capture_length = x.size(2)\n",
    "        device = torch.device(\"cuda:{0}\".format(torch.cuda.current_device()) if torch.cuda.is_available() else \"cpu\")\n",
    "        lt_matrix = torch.zeros(capture_length, capture_length, device=device)\n",
    "        for i in range(self.kernel_size//self.stride):\n",
    "            lt_matrix += F.pad(\n",
    "                torch.eye(\n",
    "                    capture_length - self.stride * i,\n",
    "                    device=device),\n",
    "                (i*self.stride,0,0,i*self.stride))\n",
    "        # must register matrix as a buffer to automatically move to GPU with model.to_device()\n",
    "        # for PyTorch v1.0.1\n",
    "        # self.register_buffer('lt_matrix', lt_matrix)\n",
    "\n",
    "        # residual branch \n",
    "        res = self.residual(x) \n",
    "         \n",
    "        # spatial convolution of incoming frame (node-wise) \n",
    "        x = self.conv(x) \n",
    " \n",
    "        # convert to the expected dimension order and add the partition dimension \n",
    "        # reshape the tensor for multiplication with the adjacency matrix \n",
    "        # (convolution output contains all partitions, stacked across the channel dimension) \n",
    "        # split into separate 4D tensors, each corresponding to a separate partition \n",
    "        x = torch.split(x, self.out_channels, dim=1) \n",
    "        # concatenate these 4D tensors across the partition dimension \n",
    "        x = torch.stack(x, -1) \n",
    "        # change the dimension order for the correct broadcating of the adjacency matrix \n",
    "        # (N,C,L,V,P) -> (N,L,P,C,V) \n",
    "        x = x.permute(0,2,4,1,3) \n",
    "        # single multiplication with the adjacency matrices (spatial selective addition, across partitions) \n",
    "        x = torch.matmul(x, A) \n",
    " \n",
    "        # sum temporally by multiplying features with the Toeplitz matrix \n",
    "        # reorder dimensions for correct broadcasted multiplication (N,L,P,C,V) -> (N,P,C,V,L) \n",
    "        x = x.permute(0,2,3,4,1) \n",
    "        x = torch.matmul(x, lt_matrix) \n",
    "        # sum across partitions (N,C,V,L) \n",
    "        x = torch.sum(x, dim=(1)) \n",
    "        # match the dimension ordering of the input (N,C,V,L) -> (N,C,L,V) \n",
    "        x = x.permute(0,1,3,2) \n",
    " \n",
    "        # normalize the output of the st-gcn operation and activate \n",
    "        x = self.bn_relu(x) \n",
    " \n",
    "        # add the branches (main + residual), activate and dropout \n",
    "        return self.do(x + res) \n",
    "\n",
    "\n",
    "\n",
    "class OriginalStgcn(nn.Module):\n",
    "    \"\"\"Original classification spatial temporal graph convolutional networks.\n",
    "\n",
    "    Data provision (batching, unfolding, etc.) is delegated to the caller. Model operates \n",
    "    on frame-by-frame basis and only requires an input buffer supplied to in the size of\n",
    "    the requested receptive field.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input data\n",
    "        num_class (int): Number of classes for the classification task\n",
    "        graph_args (dict): The arguments for building the graph\n",
    "        edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "            importance weighting to the edges of the graph\n",
    "        **kwargs (optional): Other parameters for graph convolution units\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in}, M_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "            :math:`M_{in}` is the number of instance in a frame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conf = kwargs\n",
    "\n",
    "        # load graph\n",
    "        self.graph = Graph(strategy=kwargs['strategy'], **kwargs['graph'])\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # build networks\n",
    "        spatial_kernel_size = kwargs['graph']['num_node']\n",
    "        temporal_kernel_size = kwargs['kernel'][0]\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        \n",
    "        self.data_bn = nn.BatchNorm1d(kwargs['in_feat'] * A.size(1))\n",
    "        # fcn for feature remapping of input to the network size\n",
    "        self.fcn_in = nn.Conv2d(in_channels=kwargs['in_feat'], out_channels=kwargs['in_ch'][0][0], kernel_size=1)\n",
    "\n",
    "        stack = [[st_gcn_original(\n",
    "                    in_channels=kwargs['in_ch'][i][j],\n",
    "                    out_channels=kwargs['out_ch'][i][j],\n",
    "                    kernel_size=kernel_size,\n",
    "                    partitions=A.size(0),\n",
    "                    stride=kwargs['stride'][i][j],\n",
    "                    residual=not not kwargs['residual'][i][j],\n",
    "                    dropout=kwargs['dropout'][i][j])\n",
    "                for j in range(layers_in_stage)] \n",
    "                for i, layers_in_stage in enumerate(kwargs['layers'])]\n",
    "        self.st_gcn_networks = nn.ModuleList([module for sublist in stack for module in sublist])\n",
    "\n",
    "        # initialize parameters for edge importance weighting\n",
    "        if kwargs['importance']:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(self.A.size()))\n",
    "                for _ in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        # fcn for prediction\n",
    "        self.fcn = nn.Conv2d(\n",
    "            kwargs['out_ch'][-1][-1],\n",
    "            out_channels=kwargs['num_classes'],\n",
    "            kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization\n",
    "        N, C, T, V = x.size()\n",
    "        # permutes must copy the tensor over as contiguous because .view() needs a contiguous tensor\n",
    "        # this incures extra overhead\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        # (N,V,C,T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # (N,C,T,V)\n",
    "\n",
    "        # remap the features to the network size\n",
    "        x = self.fcn_in(x)\n",
    "\n",
    "        # forward\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = checkpoint(gcn, x, self.A * importance)\n",
    "\n",
    "        # global pooling (across time L, and nodes V)\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def extract_feature(self, x):\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        # permutes must copy the tensor over as contiguous because .view() needs a contiguous tensor\n",
    "        # this incures extra overhead\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        # (N,M,V,C,T)\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "        # (N',C,T,V)\n",
    "\n",
    "        # remap the features to the network size\n",
    "        x = self.fcn_in(x)\n",
    "\n",
    "        # forward\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        # global pooling (across time L, and nodes V)\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "\n",
    "        feature = x.squeeze(-1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        output = x.squeeze(-1)\n",
    "\n",
    "        return output, feature\n",
    "\n",
    "\n",
    "class st_gcn_original(nn.Module):\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (tuple): Size of the temporal convolving kernel and graph convolving kernel\n",
    "        stride (int, optional): Stride of the temporal convolution. Default: 1\n",
    "        dropout (int, optional): Dropout rate of the final output. Default: 0\n",
    "        residual (bool, optional): If ``True``, applies a residual mechanism. Default: ``True``\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)` format\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Output graph sequence in :math:`(N, out_channels, T_{out}, V)` format\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)` format\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        partitions,\n",
    "        stride=1,\n",
    "        dropout=0,\n",
    "        residual=True):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        padding = (((kernel_size[0] - 1) // 2), 0)\n",
    "\n",
    "        self.gcn = ConvTemporalGraphical(\n",
    "            in_channels, \n",
    "            out_channels,\n",
    "            kernel_size[1],\n",
    "            partitions)\n",
    "\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                (kernel_size[0], 1),\n",
    "                stride=(stride, 1),\n",
    "                padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(dropout, inplace=True))\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=(stride, 1)),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        # graph convolution\n",
    "        x = self.gcn(x, A)\n",
    "        # temporal accumulation (but using a learnable kernel)\n",
    "        x = self.tcn(x)\n",
    "\n",
    "        return self.relu(x + res)\n",
    "\n",
    "\n",
    "class AdaptedStgcn(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional networks, adapted for segmentation.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input data\n",
    "        num_class (int): Number of classes for the classification task\n",
    "        graph_args (dict): The arguments for building the graph\n",
    "        edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "            importance weighting to the edges of the graph\n",
    "        **kwargs (optional): Other parameters for graph convolution units\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in}, M_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "            :math:`M_{in}` is the number of instance in a frame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # load graph\n",
    "        self.graph = Graph(strategy=kwargs['strategy'], **kwargs['graph'])\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # build networks\n",
    "        spatial_kernel_size = kwargs['graph']['num_node']\n",
    "        temporal_kernel_size = kwargs['kernel'][0]\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        \n",
    "        self.data_bn = nn.BatchNorm1d(kwargs['in_feat'] * A.size(1))\n",
    "        # fcn for feature remapping of input to the network size\n",
    "        self.fcn_in = nn.Conv2d(in_channels=kwargs['in_feat'], out_channels=kwargs['in_ch'][0][0], kernel_size=1)\n",
    "\n",
    "        stack = [[st_gcn_adapted(\n",
    "                    in_channels=kwargs['in_ch'][i][j],\n",
    "                    out_channels=kwargs['out_ch'][i][j],\n",
    "                    kernel_size=kernel_size,\n",
    "                    partitions=A.size(0),\n",
    "                    stride=kwargs['stride'][i][j],\n",
    "                    residual=not not kwargs['residual'][i][j],\n",
    "                    dropout=kwargs['dropout'][i][j])\n",
    "                for j in range(layers_in_stage)] \n",
    "                for i, layers_in_stage in enumerate(kwargs['layers'])]\n",
    "        self.st_gcn_networks = nn.ModuleList([module for sublist in stack for module in sublist])\n",
    "\n",
    "        # initialize parameters for edge importance weighting\n",
    "        if kwargs['importance']:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(self.A.size()))\n",
    "                for _ in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        # fcn for prediction\n",
    "        self.fcn = nn.Conv2d(\n",
    "            kwargs['out_ch'][-1][-1], \n",
    "            out_channels=kwargs['num_classes'],\n",
    "            kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization\n",
    "        N, C, T, V = x.size()\n",
    "        # permutes must copy the tensor over as contiguous because .view() needs a contiguous tensor\n",
    "        # this incures extra overhead\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        # (N,V,C,T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # (N,C,T,V)\n",
    "\n",
    "        # remap the features to the network size\n",
    "        x = self.fcn_in(x)\n",
    "\n",
    "        # forward\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = checkpoint(gcn, x, self.A * importance)\n",
    "\n",
    "        # global pooling\n",
    "        x = F.avg_pool2d(x, (1, x.size()[-1]))\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        x = x.squeeze(-1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def extract_feature(self, x):\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        # permutes must copy the tensor over as contiguous because .view() needs a contiguous tensor\n",
    "        # this incures extra overhead\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        # (N,M,V,C,T)\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "        # (N',C,T,V)\n",
    "\n",
    "        # remap the features to the network size\n",
    "        x = self.fcn_in(x)\n",
    "\n",
    "        # forward\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = checkpoint(gcn, x, self.A * importance)\n",
    "\n",
    "        # global pooling\n",
    "        x = F.avg_pool2d(x, (1, x.size()[-1]))\n",
    "\n",
    "        feature = x.squeeze(-1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        output = x.squeeze(-1)\n",
    "\n",
    "        return output, feature\n",
    "\n",
    "\n",
    "class st_gcn_adapted(nn.Module):\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (tuple): Size of the temporal convolving kernel and graph convolving kernel\n",
    "        stride (int, optional): Stride of the temporal convolution. Default: 1\n",
    "        dropout (int, optional): Dropout rate of the final output. Default: 0\n",
    "        residual (bool, optional): If ``True``, applies a residual mechanism. Default: ``True``\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)` format\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Output graph sequence in :math:`(N, out_channels, T_{out}, V)` format\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)` format\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        partitions,\n",
    "        stride=1,\n",
    "        dropout=0,\n",
    "        residual=True):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        padding = (((kernel_size[0] - 1) // 2) * stride, 0)\n",
    "\n",
    "        self.gcn = ConvTemporalGraphical(\n",
    "            in_channels, \n",
    "            out_channels,\n",
    "            kernel_size[1],\n",
    "            partitions)\n",
    "\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                (kernel_size[0], 1),\n",
    "                dilation=(stride, 1),\n",
    "                padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(dropout, inplace=True))\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        # graph convolution\n",
    "        x = self.gcn(x, A)\n",
    "        # temporal accumulation (but using a learnable kernel)\n",
    "        x = self.tcn(x)\n",
    "\n",
    "        return self.relu(x + res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce97d83-b2ae-4c81-a27c-b8a4f8430b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-level custom CLI parser\n",
    "parser = st_gcn_parser.Parser(\n",
    "    prog='main',\n",
    "    description='Script for human action segmentation processing using ST-GCN networks.',\n",
    "    epilog='TODO: add the epilog')\n",
    "\n",
    "subparsers= parser.add_subparsers(metavar='command')\n",
    "\n",
    "# train command parser (must manually update usage after changes \n",
    "# to the argument list or provide a custom formatter)\n",
    "parser_train = subparsers.add_parser(\n",
    "    'train',\n",
    "    usage=\"\"\"%(prog)s [-h]\n",
    "        \\r\\t[--config FILE]            \n",
    "        \\r\\t[--model MODEL {realtime|buffer_realtime|batch|original}]\n",
    "        \\r\\t[--strategy STRATEGY {uniform|distance|spatial}]\n",
    "        \\r\\t[--in_feat IN_FEAT]\n",
    "        \\r\\t[--stages STAGES]\n",
    "        \\r\\t[--buffer BUFFER]\n",
    "        \\r\\t[--kernel [KERNEL]]\n",
    "        \\r\\t[--segment [SEGMENT]]\n",
    "        \\r\\t[--importance]\n",
    "        \\r\\t[--latency]\n",
    "        \\r\\t[--receptive_field FIELD]\n",
    "        \\r\\t[--layers [LAYERS]]\n",
    "        \\r\\t[--in_ch [IN_CH,[...]]]\n",
    "        \\r\\t[--out_ch [OUT_CH,[...]]]\n",
    "        \\r\\t[--stride [STRIDE,[...]]]\n",
    "        \\r\\t[--residual [RESIDUAL,[...]]]\n",
    "        \\r\\t[--dropout [DROPOUT,[...]]]\n",
    "        \\r\\t[--graph FILE]\n",
    "\n",
    "        \\r\\t[--seed SEED]\n",
    "        \\r\\t[--epochs EPOCHS]\n",
    "        \\r\\t[--checkpoints [CHECKPOINTS]]\n",
    "        \\r\\t[--learning_rate RATE]\n",
    "        \\r\\t[--learning_rate_decay RATE_DECAY]\n",
    "        \\r\\t[--batch_size BATCH]\n",
    "\n",
    "        \\r\\t[--data DATA_DIR]\n",
    "        \\r\\t[--dataset_type TYPE]\n",
    "        \\r\\t[--actions FILE]\n",
    "        \\r\\t[--out OUT_DIR]\n",
    "        \\r\\t[--checkpoint CHECKPOINT]\n",
    "        \\r\\t[--log O_FILE E_FILE]\n",
    "        \\r\\t[--email EMAIL]\n",
    "        \\r\\t[-v[vv]]\"\"\",\n",
    "    help='train target ST-GCN network',\n",
    "    epilog='TODO: add the epilog')\n",
    "\n",
    "parser_train_model = parser_train.add_argument_group(\n",
    "    'model',\n",
    "    'arguments for configuring the ST-GCN model. '\n",
    "    'If an argument is not provided, defaults to value inside config file. '\n",
    "    'User can provide own config JSON file using --config argument, '\n",
    "    'but it is the user\\'s responsibility to provide all needed parameters')\n",
    "parser_train_optim = parser_train.add_argument_group(\n",
    "    'optimizer',\n",
    "    'arguments for configuring training')\n",
    "parser_train_io = parser_train.add_argument_group(\n",
    "    'IO',\n",
    "    'all miscallenous IO, log, file and path arguments')\n",
    "\n",
    "# model arguments\n",
    "parser_train_model.add_argument(\n",
    "    '--config',\n",
    "    type=str,\n",
    "    default='config/kinetics/realtime_local.json',\n",
    "    metavar='',\n",
    "    help='path to the NN config file. Must be the last argument if combined '\n",
    "        'with other CLI arguments. Provides default values for all arguments, except --log '\n",
    "        '(default: config/kinetics/realtime_local.json)')\n",
    "parser_train_model.add_argument(\n",
    "    '--model',\n",
    "    choices=['realtime','buffer_realtime','batch','original'],\n",
    "    metavar='',\n",
    "    help='type of NN model to use (default: realtime)')\n",
    "parser_train_model.add_argument(\n",
    "    '--strategy',\n",
    "    choices=['uniform','distance','spatial'],\n",
    "    metavar='',\n",
    "    help='type of graph partitioning strategy to use (default: spatial)')\n",
    "parser_train_model.add_argument(\n",
    "    '--in_feat',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of features/channels in data samples (default: 3)')\n",
    "parser_train_model.add_argument(\n",
    "    '--stages',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of ST-GCN stages to stack (default: 1)')\n",
    "parser_train_model.add_argument(\n",
    "    '--buffer',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of frames to buffer before batch processing. '\n",
    "        'Applied only when --model=buffer_realtime (default: 1)')\n",
    "parser_train_model.add_argument(\n",
    "    '--kernel',\n",
    "    type=int,\n",
    "    nargs='+',\n",
    "    metavar='',\n",
    "    help='list of temporal kernel sizes (Gamma) per stage (default: [9])')\n",
    "parser_train_model.add_argument(\n",
    "    '--segment',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='size of overlapping segments of frames to divide a trial into for '\n",
    "        'parallelizing computation (creates a new batch dimension). '\n",
    "        'Currently only supports datasets with different length trials. '\n",
    "        'Applied only when --model != original and --dataset_type=dir (default: 100)')\n",
    "parser_train_model.add_argument(\n",
    "    '--importance',\n",
    "    default=True,\n",
    "    action='store_true',\n",
    "    help='flag specifying whether ST-GCN layers have edge importance weighting '\n",
    "        '(default: True)')\n",
    "parser_train_model.add_argument(\n",
    "    '--latency',\n",
    "    default=False,\n",
    "    action='store_true',\n",
    "    help='flag specifying whether ST-GCN layers have half-buffer latency, '\n",
    "        'or non-overlapping window when --model=original (default: False)')\n",
    "parser_train_model.add_argument(\n",
    "    '--receptive_field',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of frames in a sliding window across raw inputs. '\n",
    "        'Applied only when --model=original (default: 50)')\n",
    "parser_train_model.add_argument(\n",
    "    '--layers',\n",
    "    type=int,\n",
    "    nargs='+',\n",
    "    metavar='',\n",
    "    help='list of number of ST-GCN layers per stage (default: [9])')\n",
    "parser_train_model.add_argument(\n",
    "    '--in_ch',\n",
    "    type=int,\n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of number of input channels per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --in_ch parameter multiple times '\n",
    "        '(default: [[64,64,64,64,128,128,128,256,256]])')\n",
    "parser_train_model.add_argument(\n",
    "    '--out_ch',\n",
    "    type=int, \n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of number of output channels per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --out_ch parameter multiple times '\n",
    "        '(default: [[64,64,64,128,128,128,256,256,256]])')\n",
    "parser_train_model.add_argument(\n",
    "    '--stride',\n",
    "    type=int, \n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of size of stride in temporal accumulation per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --stride parameter multiple times '\n",
    "        '(default: [[1,1,1,2,1,1,2,1,1]])')\n",
    "parser_train_model.add_argument(\n",
    "    '--residual',\n",
    "    type=int, \n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of binary flags specifying residual connection per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --residual parameter multiple times '\n",
    "        '(default: [[0,1,1,1,1,1,1,1,1]])')\n",
    "parser_train_model.add_argument(\n",
    "    '--dropout',\n",
    "    type=float,\n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of dropout values per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --dropout parameter multiple times '\n",
    "        '(default: [[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5]])')\n",
    "parser_train_model.add_argument(\n",
    "    '--graph',\n",
    "    type=str,\n",
    "    metavar='',\n",
    "    help='path to the skeleton graph specification file '\n",
    "        '(default: data/skeletons/openpose.json)')\n",
    "# optimizer arguments\n",
    "parser_train_optim.add_argument(\n",
    "    '--seed',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='seed for the random number generator (default: 1538574472)')\n",
    "parser_train_optim.add_argument(\n",
    "    '--epochs',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of epochs to train the NN over (default: 100)')\n",
    "parser_train_optim.add_argument(\n",
    "    '--checkpoints',\n",
    "    type=int,\n",
    "    nargs='+',\n",
    "    metavar='',\n",
    "    help='list of epochs to checkpoint the model at '\n",
    "        '(default: [19, 39, 59, 79, 99])')\n",
    "parser_train_optim.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    metavar='',\n",
    "    help='learning rate of the optimizer (default: 0.01)')\n",
    "parser_train_optim.add_argument(\n",
    "    '--learning_rate_decay',\n",
    "    type=float,\n",
    "    metavar='',\n",
    "    help='learning rate decay factor of the optimizer (default: 0.1)')\n",
    "parser_train_optim.add_argument(\n",
    "    '--batch_size',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of captures to process in a minibatch (default: 16)')\n",
    "# IO arguments\n",
    "parser_train_io.add_argument(\n",
    "    '--data',\n",
    "    metavar='',\n",
    "    help='path to the dataset directory (default: data/kinetics)')\n",
    "parser_train_io.add_argument(\n",
    "    '--dataset_type',\n",
    "    metavar='',\n",
    "    help='type of the dataset (default: file)')\n",
    "parser_train_io.add_argument(\n",
    "    '--actions',\n",
    "    metavar='',\n",
    "    help='path to the action classes file (default: data/kinetics/actions.txt)')\n",
    "parser_train_io.add_argument(\n",
    "    '--out',\n",
    "    metavar='',\n",
    "    help='path to the output directory (default: pretrained_models/kinetics)')\n",
    "parser_train_io.add_argument(\n",
    "    '--checkpoint',\n",
    "    type=str,\n",
    "    metavar='',\n",
    "    default=None,\n",
    "    help='path to the checkpoint to restore states from (default: None)')\n",
    "parser_train_io.add_argument(\n",
    "    '--log',\n",
    "    nargs=2,\n",
    "    type=argparse.FileType('w'),\n",
    "    # const=[t1+t2+'.txt' for t1, t2 in zip(['log.o.','log.e.'],2*[str(time.time())])],\n",
    "    default=[sys.stdout, sys.stderr],\n",
    "    metavar='',\n",
    "    help='files to log the script to. Only argument without default option in --config '\n",
    "        '(default: stdout, stderr)')\n",
    "parser_train_io.add_argument(\n",
    "    '--email',\n",
    "    type=str,\n",
    "    metavar='',\n",
    "    default=None,\n",
    "    help='email address to send update notifications to (default: None)')\n",
    "parser_train_io.add_argument(\n",
    "    '-v', '--verbose', dest='verbose',\n",
    "    action='count', \n",
    "    default=0,\n",
    "    help='level of log detail (default: 0)')\n",
    "\n",
    "# test command parser\n",
    "parser_test = subparsers.add_parser(\n",
    "    'test',\n",
    "    usage=\"\"\"%(prog)s\\n\\t[-h]\n",
    "        \\r\\t[--config FILE]            \n",
    "        \\r\\t[--model MODEL {realtime|buffer_realtime|batch|original}]\n",
    "        \\r\\t[--strategy STRATEGY {uniform|distance|spatial}]\n",
    "        \\r\\t[--in_feat IN_FEAT]\n",
    "        \\r\\t[--stages STAGES]\n",
    "        \\r\\t[--buffer BUFFER]\n",
    "        \\r\\t[--kernel [KERNEL]]\n",
    "        \\r\\t[--importance]\n",
    "        \\r\\t[--latency]\n",
    "        \\r\\t[--layers [LAYERS]]\n",
    "        \\r\\t[--in_ch [IN_CH,[...]]]\n",
    "        \\r\\t[--out_ch [OUT_CH,[...]]]\n",
    "        \\r\\t[--stride [STRIDE,[...]]]\n",
    "        \\r\\t[--residual [RESIDUAL,[...]]]\n",
    "        \\r\\t[--dropout [DROPOUT,[...]]]\n",
    "        \\r\\t[--graph FILE]\n",
    "\n",
    "        \\r\\t[--data DATA_DIR]\n",
    "        \\r\\t[--dataset_type TYPE]\n",
    "        \\r\\t[--actions FILE]\n",
    "        \\r\\t[--out OUT_DIR]\n",
    "        \\r\\t[--checkpoint CHECKPOINT]\n",
    "        \\r\\t[--log O_FILE E_FILE]\n",
    "        \\r\\t[--email EMAIL]\n",
    "        \\r\\t[-v[vv]]\"\"\",\n",
    "    help='test target ST-GCN network',\n",
    "    epilog='TODO: add the epilog')\n",
    "\n",
    "parser_test_model = parser_test.add_argument_group(\n",
    "    'model',\n",
    "    'arguments for configuring the ST-GCN model. '\n",
    "    'If an argument is not provided, defaults to value inside config file. '\n",
    "    'User can provide own config JSON file using --config argument, '\n",
    "    'but it is the user\\'s responsibility to provide all needed parameters')\n",
    "parser_test_io = parser_test.add_argument_group(\n",
    "    'IO',\n",
    "    'all miscallenous IO, log, file and path arguments')\n",
    "\n",
    "# model arguments\n",
    "parser_test_model.add_argument(\n",
    "    '--config',\n",
    "    type=str,\n",
    "    default='config/kinetics/realtime_local.json',\n",
    "    metavar='',\n",
    "    help='path to the NN config file. Must be the last argument if combined '\n",
    "        'with other CLI arguments. Provides default values for all arguments, except --log '\n",
    "        '(default: config/kinetics/realtime_local.json)')\n",
    "parser_test_model.add_argument(\n",
    "    '--model',\n",
    "    choices=['realtime','buffer_realtime','batch','original'],\n",
    "    metavar='',\n",
    "    help='type of NN model to use (default: realtime)')\n",
    "parser_test_model.add_argument(\n",
    "    '--strategy',\n",
    "    choices=['uniform','distance','spatial'],\n",
    "    metavar='',\n",
    "    help='type of graph partitioning strategy to use (default: spatial)')\n",
    "parser_test_model.add_argument(\n",
    "    '--in_feat',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of features/channels in data samples (default: 3)')\n",
    "parser_test_model.add_argument(\n",
    "    '--stages',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of ST-GCN stages to stack (default: 1)')\n",
    "parser_test_model.add_argument(\n",
    "    '--buffer',\n",
    "    type=int,\n",
    "    metavar='',\n",
    "    help='number of frames to buffer before batch processing. '\n",
    "        'Applied only when --model=buffer_realtime (default: 1)')\n",
    "parser_test_model.add_argument(\n",
    "    '--kernel',\n",
    "    type=int,\n",
    "    nargs='+',\n",
    "    metavar='',\n",
    "    help='list of temporal kernel sizes (Gamma) per stage (default: [9])')\n",
    "parser_test_model.add_argument(\n",
    "    '--importance',\n",
    "    default=True,\n",
    "    action='store_true',\n",
    "    help='flag specifying whether ST-GCN layers have edge importance weighting '\n",
    "        '(default: True)')\n",
    "parser_test_model.add_argument(\n",
    "    '--latency',\n",
    "    default=False,\n",
    "    action='store_true',\n",
    "    help='flag specifying whether ST-GCN layers have half-buffer latency '\n",
    "        '(default: False)')\n",
    "parser_test_model.add_argument(\n",
    "    '--layers',\n",
    "    type=int,\n",
    "    nargs='+',\n",
    "    metavar='',\n",
    "    help='list of number of ST-GCN layers per stage (default: [9])')\n",
    "parser_test_model.add_argument(\n",
    "    '--in_ch',\n",
    "    type=int,\n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of number of input channels per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --in_ch parameter multiple times '\n",
    "        '(default: [[64,64,64,64,128,128,128,256,256]])')\n",
    "parser_test_model.add_argument(\n",
    "    '--out_ch',\n",
    "    type=int, \n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of number of output channels per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --out_ch parameter multiple times '\n",
    "        '(default: [[64,64,64,128,128,128,256,256,256]])')\n",
    "parser_test_model.add_argument(\n",
    "    '--stride',\n",
    "    type=int, \n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of size of stride in temporal accumulation per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --stride parameter multiple times '\n",
    "        '(default: [[1,1,1,2,1,1,2,1,1]])')\n",
    "parser_test_model.add_argument(\n",
    "    '--residual',\n",
    "    type=int, \n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of binary flags specifying residual connection per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --residual parameter multiple times '\n",
    "        '(default: [[0,1,1,1,1,1,1,1,1]])')\n",
    "parser_test_model.add_argument(\n",
    "    '--dropout',\n",
    "    type=float,\n",
    "    nargs='+',\n",
    "    action='append',\n",
    "    metavar='',\n",
    "    help='list of dropout values per ST-GCN layer per stage. '\n",
    "        'For multi-stage, pass --dropout parameter multiple times '\n",
    "        '(default: [[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5]])')\n",
    "parser_test_model.add_argument(\n",
    "    '--graph',\n",
    "    type=str,\n",
    "    metavar='',\n",
    "    help='path to the skeleton graph specification file '\n",
    "        '(default: data/skeletons/openpose.json)')\n",
    "# IO arguments\n",
    "parser_test_io.add_argument(\n",
    "    '--data',\n",
    "    metavar='',\n",
    "    help='path to the dataset directory (default: data/kinetics)')\n",
    "parser_test_io.add_argument(\n",
    "    '--dataset_type',\n",
    "    metavar='',\n",
    "    help='type of the dataset (default: file)')\n",
    "parser_test_io.add_argument(\n",
    "    '--actions',\n",
    "    metavar='',\n",
    "    help='path to the action classes file (default: data/kinetics/actions.txt)')\n",
    "parser_test_io.add_argument(\n",
    "    '--out',\n",
    "    metavar='',\n",
    "    help='path to the output directory (default: pretrained_models/kinetics)')\n",
    "parser_test_io.add_argument(\n",
    "    '--checkpoint',\n",
    "    type=str,\n",
    "    metavar='',\n",
    "    default=None,\n",
    "    help='path to the checkpoint to restore states from (default: None)')\n",
    "parser_test_io.add_argument(\n",
    "    '--log',\n",
    "    nargs=2,\n",
    "    type=argparse.FileType('w'),\n",
    "    # const=[t1+t2+'.txt' for t1, t2 in zip(['log.o.','log.e.'],2*[str(time.time())])],\n",
    "    default=[sys.stdout, sys.stderr],\n",
    "    metavar='',\n",
    "    help='files to log the script to. Only argument without default option in --config '\n",
    "        '(default: stdout, stderr)')\n",
    "parser_test_io.add_argument(\n",
    "    '--email',\n",
    "    type=str,\n",
    "    metavar='',\n",
    "    default=None,\n",
    "    help='email address to send update notifications to (default: None)')\n",
    "parser_test_io.add_argument(\n",
    "    '-v', '--verbose', dest='verbose',\n",
    "    action='count', \n",
    "    default=0,\n",
    "    help='level of log detail (default: 0)')\n",
    "\n",
    "##################################################################\n",
    "# benchmark command parser\n",
    "# TODO: setup all the needed CLI arguments\n",
    "parser_benchmark = subparsers.add_parser(\n",
    "    'benchmark',\n",
    "    usage=\"\"\"%(prog)s\\n\\t[-h]\n",
    "\n",
    "        \"\"\",\n",
    "    help='benchmark target ST-GCN network against baseline(s)',\n",
    "    epilog='TODO: add the epilog')\n",
    "##################################################################\n",
    "\n",
    "parser_train.set_defaults(func=train)\n",
    "parser_test.set_defaults(func=test)\n",
    "parser_benchmark.set_defaults(func=benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5853e2-f220-473a-a248-6e601a5cbfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# parse the arguments\u001b[39;00m\n\u001b[1;32m      2\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain --epochs 20 --batch_size 32 --config config/pku-mmd/adapted_vsc.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m----> 3\u001b[0m \u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 703\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining started\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, file\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlog[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# perform the training\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# (the model is trained on all skeletons in the scene, simultaneously)\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed in: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, file\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlog[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    712\u001b[0m os\u001b[38;5;241m.\u001b[39msystem(\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmail -s \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m]: $PBS_JOBNAME - COMPLETED\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m <<< \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    715\u001b[0m         os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPBS_JOBID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    716\u001b[0m         args\u001b[38;5;241m.\u001b[39memail))\n",
      "Cell \u001b[0;32mIn[1], line 365\u001b[0m, in \u001b[0;36mProcessor.train\u001b[0;34m(self, save_dir, train_dataloader, val_dataloader, device, epochs, checkpoints, checkpoint, learning_rate, learning_rate_decay, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# update parameters based on the computed gradients\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# clear the loss\u001b[39;00m\n\u001b[1;32m    368\u001b[0m ce_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 365\u001b[0m, in \u001b[0;36mProcessor.train\u001b[0;34m(self, save_dir, train_dataloader, val_dataloader, device, epochs, checkpoints, checkpoint, learning_rate, learning_rate_decay, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# update parameters based on the computed gradients\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# clear the loss\u001b[39;00m\n\u001b[1;32m    368\u001b[0m ce_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/leuven/341/vsc34153/miniconda3/envs/conda-pytorch-interactive/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/data/leuven/341/vsc34153/miniconda3/envs/conda-pytorch-interactive/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parse the arguments\n",
    "args = parser.parse_args(\"train --epochs 20 --batch_size 32 --config config/pku-mmd/adapted_vsc.json\".split())\n",
    "args.func(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6bbf27-fc48-45a1-bc39-64d56ea2db52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
